{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'agent'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d5ba6ad0bd3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0magent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrandom\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'agent'"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, LeakyReLU, Input, merge, Reshape, Lambda, BatchNormalization, Dropout\n",
    "from keras.regularizers import L1L2\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "from keras.optimizers import Adam\n",
    "import itertools\n",
    "from keras import backend as K\n",
    "import os\n",
    "from agent import Agent\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "def flatten_spaces(space):\n",
    "    if isinstance(space, spaces.Tuple):\n",
    "        return list(itertools.chain.from_iterable(flatten_spaces(s) for s in space.spaces))\n",
    "    else:\n",
    "        return [space]\n",
    "\n",
    "\n",
    "def calc_input_dim(space):\n",
    "    dims = []\n",
    "    print (\"Space: {}\".format(space))\n",
    "    print (\"Flattened: {}\".format(flatten_spaces(space)))\n",
    "    for i in flatten_spaces(space):\n",
    "        if isinstance(i, spaces.Discrete):\n",
    "            dims.append(i.n)\n",
    "        elif isinstance(i, spaces.Box):\n",
    "            dims.append(np.prod(i.shape))\n",
    "        else:\n",
    "            raise NotImplementedError(\"Only Discrete and Box input spaces currently supported\")\n",
    "    return np.sum(dims)\n",
    "\n",
    "\n",
    "def concat_input(observation, input_space):\n",
    "    if isinstance(input_space, spaces.Tuple):\n",
    "        return np.hstack([np.array(concat_input(obs, space)) for obs, space in\n",
    "                          zip(observation, input_space.spaces)])\n",
    "    elif isinstance(input_space, spaces.Discrete):\n",
    "        return to_categorical(observation, nb_classes=input_space.n).reshape((1, -1))\n",
    "    elif isinstance(input_space, spaces.Box):\n",
    "        return observation.reshape((1, -1))\n",
    "    else:\n",
    "        raise NotImplementedError(\"Only Discrete and Box input spaces currently supported\")\n",
    "\n",
    "\n",
    "class DQN(Agent):\n",
    "    def __init__(self, input_space, action_space, memory_size=10, replay_size=64, discount=0.95, seed=None,\n",
    "                 optimizer=None):\n",
    "        super(DQN, self).__init__(input_space, action_space, seed=seed)\n",
    "        self.input_dim = calc_input_dim(input_space)\n",
    "        self.memory_size = memory_size\n",
    "        self.replay_size = replay_size\n",
    "        self.discount = K.variable(K.cast_to_floatx(discount))\n",
    "        self.step = 0\n",
    "        self.data_dim = self.input_dim * self.memory_size\n",
    "        self.replay = []\n",
    "        self.new_episode()\n",
    "        if optimizer is None:\n",
    "            optimizer = Adam(1e-4, decay=1e-6)\n",
    "        self.optimizer = optimizer\n",
    "        if not isinstance(action_space, spaces.Discrete):\n",
    "            raise NotImplementedError(\"Only Discrete action spaces supported\")\n",
    "        self.build_network()\n",
    "\n",
    "    def new_episode(self):\n",
    "        self.memory = [np.zeros((1, self.input_dim)) for i in range(self.memory_size)]\n",
    "        self.observation = None\n",
    "        self.last_observation = None\n",
    "\n",
    "    def build_network(self):\n",
    "        hidden_dim = 1024\n",
    "        reg = lambda: L1L2Regularizer(l1=1e-9, l2=1e-9)\n",
    "        x = Input(shape=(self.data_dim,), name=\"x\")\n",
    "        h = x\n",
    "        h = Dense(hidden_dim, W_regularizer=reg())(h)\n",
    "        h = Dropout(0.5)(h)\n",
    "        #h = BatchNormalization(mode=1)(h)\n",
    "        h = LeakyReLU(0.2)(h)\n",
    "        h = Dense(hidden_dim / 2, W_regularizer=reg())(h)\n",
    "        h = Dropout(0.5)(h)\n",
    "        #h = BatchNormalization(mode=1)(h)\n",
    "        h = LeakyReLU(0.2)(h)\n",
    "        h = Dense(hidden_dim / 4, W_regularizer=reg())(h)\n",
    "        h = Dropout(0.5)(h)\n",
    "        #h = BatchNormalization(mode=1)(h)\n",
    "        h = LeakyReLU(0.2)(h)\n",
    "        y = Dense(self.action_space.n, W_regularizer=reg())(h)\n",
    "        # Q(s, a)\n",
    "        self.Q = Model(x, y, name=\"Q\")\n",
    "\n",
    "        action = Input(shape=(1,), dtype='int32', name=\"action\")\n",
    "        \"\"\"\n",
    "        selected_y = merge([y, action],\n",
    "                           mode=lambda z: K.sum(K.one_hot(K.reshape(z[1], (-1,)), K.shape(z[0])[1]) * z[0], axis=-1,\n",
    "                                                keepdims=True), output_shape=lambda z: z[1])\n",
    "                                                \"\"\"\n",
    "        selected_y = merge([y, action],\n",
    "                           mode=lambda z: K.reshape(z[0][K.arange(K.shape(z[0])[0]), K.reshape(z[1], (-1,))], (-1, 1)),\n",
    "                           output_shape=lambda z: z[1])\n",
    "\n",
    "        self.Q_s = Model([x, action], selected_y, name=\"Q_s\")\n",
    "\n",
    "        value = Lambda(lambda z: K.max(z, axis=-1, keepdims=True), output_shape=lambda z: (z[0], 1))(y)\n",
    "        self.V = Model(x, value, name=\"V\")\n",
    "\n",
    "        x_prime = Input(shape=(self.data_dim,), name=\"x_prime\")\n",
    "        done = Input(shape=(1,), name=\"done\", dtype=\"int32\")\n",
    "        v_prime = Lambda(lambda z: K.stop_gradient(z), output_shape=lambda z: z)(self.V(x_prime))\n",
    "        # v_prime = self.V(x_prime)\n",
    "        q = self.Q_s([x, action])\n",
    "\n",
    "        r_pred = merge([q, v_prime, done], mode=lambda z: z[0] - ((1 - z[2]) * self.discount * z[1]),\n",
    "                       output_shape=lambda z: z[0])\n",
    "\n",
    "        self.training_model = Model([x, action, x_prime, done], r_pred, name=\"training_model\")\n",
    "\n",
    "        self.training_model.compile(self.optimizer, \"mean_squared_error\")\n",
    "\n",
    "    def observe(self, observation):\n",
    "        observation = concat_input(observation, self.input_space)\n",
    "        self.memory = self.memory[1:] + [observation]\n",
    "        self.last_observation = self.observation\n",
    "        self.observation = np.hstack(self.memory)\n",
    "\n",
    "    def act(self):\n",
    "        preds = self.Q.predict(self.observation.reshape((1, -1))).reshape((-1,))\n",
    "        action = np.argmax(preds)\n",
    "        return action\n",
    "\n",
    "    def combined_replay(self):\n",
    "        return [np.vstack(x[i] for x in self.replay) for i in range(5)]\n",
    "\n",
    "    def learn(self, action, reward, done):\n",
    "        datum = [self.last_observation, action, self.observation, [[1]] if done else [[0]], reward]\n",
    "        self.replay.append(datum)\n",
    "        if len(self.replay) > self.replay_size:\n",
    "            self.replay.pop(0)\n",
    "        # shuffle(self.replay)\n",
    "        data = self.combined_replay()\n",
    "        loss = self.training_model.train_on_batch(data[0:4], data[4])\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def save(self, filepath):\n",
    "        dirpath = os.path.dirname(filepath)\n",
    "        if not os.path.exists(dirpath):\n",
    "            os.makedirs(dirpath)\n",
    "        self.Q.save_weights(filepath)\n",
    "\n",
    "    def load(self, filepath):\n",
    "        self.Q.load_weights(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
